Seed set to 0
Reading camera 1/279Reading camera 2/279Reading camera 3/279Reading camera 4/279Reading camera 5/279Reading camera 6/279Reading camera 7/279Reading camera 8/279Reading camera 9/279Reading camera 10/279Reading camera 11/279Reading camera 12/279Reading camera 13/279Reading camera 14/279Reading camera 15/279Reading camera 16/279Reading camera 17/279Reading camera 18/279Reading camera 19/279Reading camera 20/279Reading camera 21/279Reading camera 22/279Reading camera 23/279Reading camera 24/279Reading camera 25/279Reading camera 26/279Reading camera 27/279Reading camera 28/279Reading camera 29/279Reading camera 30/279Reading camera 31/279Reading camera 32/279Reading camera 33/279Reading camera 34/279Reading camera 35/279Reading camera 36/279Reading camera 37/279Reading camera 38/279Reading camera 39/279Reading camera 40/279Reading camera 41/279Reading camera 42/279Reading camera 43/279Reading camera 44/279Reading camera 45/279Reading camera 46/279Reading camera 47/279Reading camera 48/279Reading camera 49/279Reading camera 50/279Reading camera 51/279Reading camera 52/279Reading camera 53/279Reading camera 54/279Reading camera 55/279Reading camera 56/279Reading camera 57/279Reading camera 58/279Reading camera 59/279Reading camera 60/279Reading camera 61/279Reading camera 62/279Reading camera 63/279Reading camera 64/279Reading camera 65/279Reading camera 66/279Reading camera 67/279Reading camera 68/279Reading camera 69/279Reading camera 70/279Reading camera 71/279Reading camera 72/279Reading camera 73/279Reading camera 74/279Reading camera 75/279Reading camera 76/279Reading camera 77/279Reading camera 78/279Reading camera 79/279Reading camera 80/279Reading camera 81/279Reading camera 82/279Reading camera 83/279Reading camera 84/279Reading camera 85/279Reading camera 86/279Reading camera 87/279Reading camera 88/279Reading camera 89/279Reading camera 90/279Reading camera 91/279Reading camera 92/279Reading camera 93/279Reading camera 94/279Reading camera 95/279Reading camera 96/279Reading camera 97/279Reading camera 98/279Reading camera 99/279Reading camera 100/279Reading camera 101/279Reading camera 102/279Reading camera 103/279Reading camera 104/279Reading camera 105/279Reading camera 106/279Reading camera 107/279Reading camera 108/279Reading camera 109/279Reading camera 110/279Reading camera 111/279Reading camera 112/279Reading camera 113/279Reading camera 114/279Reading camera 115/279Reading camera 116/279Reading camera 117/279Reading camera 118/279Reading camera 119/279Reading camera 120/279Reading camera 121/279Reading camera 122/279Reading camera 123/279Reading camera 124/279Reading camera 125/279Reading camera 126/279Reading camera 127/279Reading camera 128/279Reading camera 129/279Reading camera 130/279Reading camera 131/279Reading camera 132/279Reading camera 133/279Reading camera 134/279Reading camera 135/279Reading camera 136/279Reading camera 137/279Reading camera 138/279Reading camera 139/279Reading camera 140/279Reading camera 141/279Reading camera 142/279Reading camera 143/279Reading camera 144/279Reading camera 145/279Reading camera 146/279Reading camera 147/279Reading camera 148/279Reading camera 149/279Reading camera 150/279Reading camera 151/279Reading camera 152/279Reading camera 153/279Reading camera 154/279Reading camera 155/279Reading camera 156/279Reading camera 157/279Reading camera 158/279Reading camera 159/279Reading camera 160/279Reading camera 161/279Reading camera 162/279Reading camera 163/279Reading camera 164/279Reading camera 165/279Reading camera 166/279Reading camera 167/279Reading camera 168/279Reading camera 169/279Reading camera 170/279Reading camera 171/279Reading camera 172/279Reading camera 173/279Reading camera 174/279Reading camera 175/279Reading camera 176/279Reading camera 177/279Reading camera 178/279Reading camera 179/279Reading camera 180/279Reading camera 181/279Reading camera 182/279Reading camera 183/279Reading camera 184/279Reading camera 185/279Reading camera 186/279Reading camera 187/279Reading camera 188/279Reading camera 189/279Reading camera 190/279Reading camera 191/279Reading camera 192/279Reading camera 193/279Reading camera 194/279Reading camera 195/279Reading camera 196/279Reading camera 197/279Reading camera 198/279Reading camera 199/279Reading camera 200/279Reading camera 201/279Reading camera 202/279Reading camera 203/279Reading camera 204/279Reading camera 205/279Reading camera 206/279Reading camera 207/279Reading camera 208/279Reading camera 209/279Reading camera 210/279Reading camera 211/279Reading camera 212/279Reading camera 213/279Reading camera 214/279Reading camera 215/279Reading camera 216/279Reading camera 217/279Reading camera 218/279Reading camera 219/279Reading camera 220/279Reading camera 221/279Reading camera 222/279Reading camera 223/279Reading camera 224/279Reading camera 225/279Reading camera 226/279Reading camera 227/279Reading camera 228/279Reading camera 229/279Reading camera 230/279Reading camera 231/279Reading camera 232/279Reading camera 233/279Reading camera 234/279Reading camera 235/279Reading camera 236/279Reading camera 237/279Reading camera 238/279Reading camera 239/279Reading camera 240/279Reading camera 241/279Reading camera 242/279Reading camera 243/279Reading camera 244/279Reading camera 245/279Reading camera 246/279Reading camera 247/279Reading camera 248/279Reading camera 249/279Reading camera 250/279Reading camera 251/279Reading camera 252/279Reading camera 253/279Reading camera 254/279Reading camera 255/279Reading camera 256/279Reading camera 257/279Reading camera 258/279Reading camera 259/279Reading camera 260/279Reading camera 261/279Reading camera 262/279Reading camera 263/279Reading camera 264/279Reading camera 265/279Reading camera 266/279Reading camera 267/279Reading camera 268/279Reading camera 269/279Reading camera 270/279Reading camera 271/279Reading camera 272/279Reading camera 273/279Reading camera 274/279Reading camera 275/279Reading camera 276/279Reading camera 277/279Reading camera 278/279Reading camera 279/279
Reading camera 1/279Reading camera 2/279Reading camera 3/279Reading camera 4/279Reading camera 5/279Reading camera 6/279Reading camera 7/279Reading camera 8/279Reading camera 9/279Reading camera 10/279Reading camera 11/279Reading camera 12/279Reading camera 13/279Reading camera 14/279Reading camera 15/279Reading camera 16/279Reading camera 17/279Reading camera 18/279Reading camera 19/279Reading camera 20/279Reading camera 21/279Reading camera 22/279Reading camera 23/279Reading camera 24/279Reading camera 25/279Reading camera 26/279Reading camera 27/279Reading camera 28/279Reading camera 29/279Reading camera 30/279Reading camera 31/279Reading camera 32/279Reading camera 33/279Reading camera 34/279Reading camera 35/279Reading camera 36/279Reading camera 37/279Reading camera 38/279Reading camera 39/279Reading camera 40/279Reading camera 41/279Reading camera 42/279Reading camera 43/279Reading camera 44/279Reading camera 45/279Reading camera 46/279Reading camera 47/279Reading camera 48/279Reading camera 49/279Reading camera 50/279Reading camera 51/279Reading camera 52/279Reading camera 53/279Reading camera 54/279Reading camera 55/279Reading camera 56/279Reading camera 57/279Reading camera 58/279Reading camera 59/279Reading camera 60/279Reading camera 61/279Reading camera 62/279Reading camera 63/279Reading camera 64/279Reading camera 65/279Reading camera 66/279Reading camera 67/279Reading camera 68/279Reading camera 69/279Reading camera 70/279Reading camera 71/279Reading camera 72/279Reading camera 73/279Reading camera 74/279Reading camera 75/279Reading camera 76/279Reading camera 77/279Reading camera 78/279Reading camera 79/279Reading camera 80/279Reading camera 81/279Reading camera 82/279Reading camera 83/279Reading camera 84/279Reading camera 85/279Reading camera 86/279Reading camera 87/279Reading camera 88/279Reading camera 89/279Reading camera 90/279Reading camera 91/279Reading camera 92/279Reading camera 93/279Reading camera 94/279Reading camera 95/279Reading camera 96/279Reading camera 97/279Reading camera 98/279Reading camera 99/279Reading camera 100/279Reading camera 101/279Reading camera 102/279Reading camera 103/279Reading camera 104/279Reading camera 105/279Reading camera 106/279Reading camera 107/279Reading camera 108/279Reading camera 109/279Reading camera 110/279Reading camera 111/279Reading camera 112/279Reading camera 113/279Reading camera 114/279Reading camera 115/279Reading camera 116/279Reading camera 117/279Reading camera 118/279Reading camera 119/279Reading camera 120/279Reading camera 121/279Reading camera 122/279Reading camera 123/279Reading camera 124/279Reading camera 125/279Reading camera 126/279Reading camera 127/279Reading camera 128/279Reading camera 129/279Reading camera 130/279Reading camera 131/279Reading camera 132/279Reading camera 133/279Reading camera 134/279Reading camera 135/279Reading camera 136/279Reading camera 137/279Reading camera 138/279Reading camera 139/279Reading camera 140/279Reading camera 141/279Reading camera 142/279Reading camera 143/279Reading camera 144/279Reading camera 145/279Reading camera 146/279Reading camera 147/279Reading camera 148/279Reading camera 149/279Reading camera 150/279Reading camera 151/279Reading camera 152/279Reading camera 153/279Reading camera 154/279Reading camera 155/279Reading camera 156/279Reading camera 157/279Reading camera 158/279Reading camera 159/279Reading camera 160/279Reading camera 161/279Reading camera 162/279Reading camera 163/279Reading camera 164/279Reading camera 165/279Reading camera 166/279Reading camera 167/279Reading camera 168/279Reading camera 169/279Reading camera 170/279Reading camera 171/279Reading camera 172/279Reading camera 173/279Reading camera 174/279Reading camera 175/279Reading camera 176/279Reading camera 177/279Reading camera 178/279Reading camera 179/279Reading camera 180/279Reading camera 181/279Reading camera 182/279Reading camera 183/279Reading camera 184/279Reading camera 185/279Reading camera 186/279Reading camera 187/279Reading camera 188/279Reading camera 189/279Reading camera 190/279Reading camera 191/279Reading camera 192/279Reading camera 193/279Reading camera 194/279Reading camera 195/279Reading camera 196/279Reading camera 197/279Reading camera 198/279Reading camera 199/279Reading camera 200/279Reading camera 201/279Reading camera 202/279Reading camera 203/279Reading camera 204/279Reading camera 205/279Reading camera 206/279Reading camera 207/279Reading camera 208/279Reading camera 209/279Reading camera 210/279Reading camera 211/279Reading camera 212/279Reading camera 213/279Reading camera 214/279Reading camera 215/279Reading camera 216/279Reading camera 217/279Reading camera 218/279Reading camera 219/279Reading camera 220/279Reading camera 221/279Reading camera 222/279Reading camera 223/279Reading camera 224/279Reading camera 225/279Reading camera 226/279Reading camera 227/279Reading camera 228/279Reading camera 229/279Reading camera 230/279Reading camera 231/279Reading camera 232/279Reading camera 233/279Reading camera 234/279Reading camera 235/279Reading camera 236/279Reading camera 237/279Reading camera 238/279Reading camera 239/279Reading camera 240/279Reading camera 241/279Reading camera 242/279Reading camera 243/279Reading camera 244/279Reading camera 245/279Reading camera 246/279Reading camera 247/279Reading camera 248/279Reading camera 249/279Reading camera 250/279Reading camera 251/279Reading camera 252/279Reading camera 253/279Reading camera 254/279Reading camera 255/279Reading camera 256/279Reading camera 257/279Reading camera 258/279Reading camera 259/279Reading camera 260/279Reading camera 261/279Reading camera 262/279Reading camera 263/279Reading camera 264/279Reading camera 265/279Reading camera 266/279Reading camera 267/279Reading camera 268/279Reading camera 269/279Reading camera 270/279Reading camera 271/279Reading camera 272/279Reading camera 273/279Reading camera 274/279Reading camera 275/279Reading camera 276/279Reading camera 277/279Reading camera 278/279Reading camera 279/279/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[32m[INFO] Using 16bit Automatic Mixed Precision (AMP)[0m
[32m[INFO] GPU available: True (cuda), used: True[0m
[32m[INFO] TPU available: False, using: 0 TPU cores[0m
[32m[INFO] IPU available: False, using: 0 IPUs[0m
[32m[INFO] HPU available: False, using: 0 HPUs[0m
[32m[INFO] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0][0m
[32m[INFO] 
  | Name            | Type                 | Params
---------------------------------------------------------
0 | perceptual_loss | PerceptualLoss       | 14.7 M
1 | text_segmentor  | LangSAMTextSegmentor | 0     
---------------------------------------------------------
0         Trainable params
14.7 M    Non-trainable params
14.7 M    Total params
58.865    Total estimated model params size (MB)[0m
[32m[INFO] Validation results will be saved to outputs/dge/turn_the_dozer_into_red@20240611-143545/save[0m

loaded pretrained LPIPS loss from threestudio/utils/lpips/vgg.pth
final text_encoder_type: bert-base-uncased
Model loaded from /data2/.cache/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth 
 => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight'])
  0%|          | 0/279 [00:00<?, ?it/s]  0%|          | 1/279 [00:00<00:36,  7.55it/s]  1%|          | 3/279 [00:00<00:25, 11.00it/s]  2%|▏         | 5/279 [00:00<00:22, 11.93it/s]  3%|▎         | 7/279 [00:00<00:20, 13.49it/s]  3%|▎         | 9/279 [00:00<00:19, 14.11it/s]  4%|▍         | 11/279 [00:00<00:20, 13.37it/s]  5%|▍         | 13/279 [00:01<00:20, 13.27it/s]  5%|▌         | 15/279 [00:01<00:20, 12.91it/s]  6%|▌         | 17/279 [00:01<00:19, 13.54it/s]  7%|▋         | 19/279 [00:01<00:18, 13.70it/s]  8%|▊         | 21/279 [00:01<00:18, 13.73it/s]  8%|▊         | 23/279 [00:01<00:18, 14.01it/s]  9%|▉         | 25/279 [00:01<00:17, 14.34it/s] 10%|▉         | 27/279 [00:01<00:17, 14.71it/s] 10%|█         | 29/279 [00:02<00:16, 14.84it/s] 11%|█         | 31/279 [00:02<00:15, 15.54it/s] 12%|█▏        | 33/279 [00:02<00:15, 15.80it/s] 13%|█▎        | 35/279 [00:02<00:15, 15.53it/s] 13%|█▎        | 37/279 [00:02<00:15, 15.49it/s] 14%|█▍        | 39/279 [00:02<00:15, 15.67it/s] 15%|█▍        | 41/279 [00:02<00:15, 15.81it/s] 15%|█▌        | 43/279 [00:02<00:14, 16.05it/s] 16%|█▌        | 45/279 [00:03<00:14, 15.92it/s] 17%|█▋        | 47/279 [00:03<00:14, 15.83it/s] 18%|█▊        | 49/279 [00:03<00:14, 15.77it/s] 18%|█▊        | 51/279 [00:03<00:14, 15.58it/s] 19%|█▉        | 53/279 [00:03<00:13, 16.21it/s] 20%|██        | 56/279 [00:03<00:12, 17.74it/s] 21%|██        | 58/279 [00:03<00:12, 17.77it/s] 22%|██▏       | 61/279 [00:04<00:11, 18.29it/s] 23%|██▎       | 63/279 [00:04<00:12, 17.84it/s] 23%|██▎       | 65/279 [00:04<00:12, 17.34it/s] 24%|██▍       | 67/279 [00:04<00:11, 17.82it/s] 25%|██▍       | 69/279 [00:04<00:12, 16.97it/s] 25%|██▌       | 71/279 [00:04<00:11, 17.40it/s] 26%|██▌       | 73/279 [00:04<00:11, 17.71it/s] 27%|██▋       | 75/279 [00:04<00:11, 17.91it/s] 28%|██▊       | 77/279 [00:04<00:12, 16.05it/s] 28%|██▊       | 79/279 [00:05<00:13, 15.34it/s] 29%|██▉       | 81/279 [00:05<00:13, 14.25it/s] 30%|██▉       | 83/279 [00:05<00:14, 13.90it/s] 31%|███       | 86/279 [00:05<00:12, 15.97it/s] 32%|███▏      | 88/279 [00:05<00:12, 15.23it/s] 32%|███▏      | 90/279 [00:05<00:11, 15.94it/s] 33%|███▎      | 93/279 [00:06<00:11, 16.82it/s] 34%|███▍      | 95/279 [00:06<00:11, 16.08it/s] 35%|███▍      | 97/279 [00:06<00:11, 16.23it/s] 35%|███▌      | 99/279 [00:06<00:11, 16.35it/s] 36%|███▌      | 101/279 [00:06<00:10, 16.63it/s] 37%|███▋      | 104/279 [00:06<00:09, 18.67it/s] 38%|███▊      | 107/279 [00:06<00:08, 19.54it/s] 39%|███▉      | 110/279 [00:06<00:08, 20.69it/s] 41%|████      | 113/279 [00:07<00:07, 21.11it/s] 42%|████▏     | 116/279 [00:07<00:07, 21.60it/s] 43%|████▎     | 119/279 [00:07<00:07, 21.93it/s] 44%|████▎     | 122/279 [00:07<00:07, 22.17it/s] 45%|████▍     | 125/279 [00:07<00:06, 22.34it/s] 46%|████▌     | 128/279 [00:07<00:08, 18.58it/s] 47%|████▋     | 130/279 [00:07<00:08, 17.40it/s] 47%|████▋     | 132/279 [00:08<00:08, 17.22it/s] 48%|████▊     | 134/279 [00:08<00:08, 17.53it/s] 49%|████▉     | 137/279 [00:08<00:07, 18.58it/s] 50%|█████     | 140/279 [00:08<00:07, 19.28it/s] 51%|█████     | 142/279 [00:08<00:07, 17.47it/s] 52%|█████▏    | 144/279 [00:08<00:07, 16.96it/s] 52%|█████▏    | 146/279 [00:08<00:07, 17.03it/s] 53%|█████▎    | 148/279 [00:08<00:07, 16.72it/s] 54%|█████▍    | 150/279 [00:09<00:07, 16.29it/s] 54%|█████▍    | 152/279 [00:09<00:07, 15.95it/s] 55%|█████▌    | 154/279 [00:09<00:08, 15.56it/s] 56%|█████▌    | 156/279 [00:09<00:08, 15.30it/s] 57%|█████▋    | 158/279 [00:09<00:07, 16.13it/s] 58%|█████▊    | 161/279 [00:09<00:06, 18.35it/s] 59%|█████▉    | 164/279 [00:09<00:05, 19.51it/s] 60%|█████▉    | 167/279 [00:10<00:05, 20.49it/s] 61%|██████    | 170/279 [00:10<00:05, 20.97it/s] 62%|██████▏   | 173/279 [00:10<00:05, 18.78it/s] 63%|██████▎   | 175/279 [00:10<00:06, 16.85it/s] 63%|██████▎   | 177/279 [00:10<00:05, 17.50it/s] 64%|██████▍   | 179/279 [00:10<00:05, 18.10it/s] 65%|██████▌   | 182/279 [00:10<00:05, 18.33it/s] 66%|██████▌   | 184/279 [00:10<00:05, 17.40it/s] 67%|██████▋   | 186/279 [00:11<00:05, 17.51it/s] 67%|██████▋   | 188/279 [00:11<00:05, 16.94it/s] 68%|██████▊   | 191/279 [00:11<00:05, 17.32it/s] 69%|██████▉   | 193/279 [00:11<00:04, 17.26it/s] 70%|██████▉   | 195/279 [00:11<00:05, 16.74it/s] 71%|███████   | 197/279 [00:11<00:05, 16.01it/s] 71%|███████▏  | 199/279 [00:11<00:05, 14.85it/s] 72%|███████▏  | 201/279 [00:12<00:05, 13.98it/s] 73%|███████▎  | 203/279 [00:12<00:05, 14.26it/s] 73%|███████▎  | 205/279 [00:12<00:05, 13.92it/s] 75%|███████▍  | 208/279 [00:12<00:04, 15.97it/s] 75%|███████▌  | 210/279 [00:12<00:04, 16.73it/s] 76%|███████▌  | 212/279 [00:12<00:03, 17.37it/s] 77%|███████▋  | 214/279 [00:12<00:04, 15.36it/s] 77%|███████▋  | 216/279 [00:13<00:04, 14.18it/s] 78%|███████▊  | 218/279 [00:13<00:04, 14.21it/s] 79%|███████▉  | 220/279 [00:13<00:03, 14.85it/s] 80%|███████▉  | 222/279 [00:13<00:03, 14.80it/s] 80%|████████  | 224/279 [00:13<00:03, 13.81it/s] 81%|████████  | 226/279 [00:13<00:03, 13.83it/s] 82%|████████▏ | 228/279 [00:13<00:04, 12.26it/s] 82%|████████▏ | 230/279 [00:14<00:03, 13.19it/s] 83%|████████▎ | 232/279 [00:14<00:03, 14.17it/s] 84%|████████▍ | 234/279 [00:14<00:03, 13.85it/s] 85%|████████▍ | 236/279 [00:14<00:02, 14.34it/s] 85%|████████▌ | 238/279 [00:14<00:02, 13.73it/s] 86%|████████▌ | 240/279 [00:14<00:02, 13.13it/s] 87%|████████▋ | 242/279 [00:15<00:02, 12.74it/s] 87%|████████▋ | 244/279 [00:15<00:02, 12.31it/s] 88%|████████▊ | 246/279 [00:15<00:02, 12.16it/s] 89%|████████▉ | 248/279 [00:15<00:02, 12.09it/s] 90%|████████▉ | 250/279 [00:15<00:02, 12.83it/s] 90%|█████████ | 252/279 [00:15<00:02, 13.24it/s] 91%|█████████ | 254/279 [00:15<00:01, 12.84it/s] 92%|█████████▏| 256/279 [00:16<00:01, 13.57it/s] 92%|█████████▏| 258/279 [00:16<00:01, 14.91it/s] 93%|█████████▎| 260/279 [00:16<00:01, 15.95it/s] 94%|█████████▍| 262/279 [00:16<00:01, 14.48it/s] 95%|█████████▍| 264/279 [00:16<00:01, 13.27it/s] 95%|█████████▌| 266/279 [00:16<00:00, 13.34it/s] 96%|█████████▌| 268/279 [00:16<00:00, 13.53it/s] 97%|█████████▋| 271/279 [00:17<00:00, 15.53it/s] 98%|█████████▊| 273/279 [00:17<00:00, 15.42it/s] 99%|█████████▊| 275/279 [00:17<00:00, 16.35it/s] 99%|█████████▉| 277/279 [00:17<00:00, 14.27it/s]100%|██████████| 279/279 [00:17<00:00, 12.89it/s]100%|██████████| 279/279 [00:17<00:00, 15.76it/s]
[32m[INFO] Segmentation with prompt: dozer[0m
Segment with prompt: dozer
  0%|          | 0/7 [00:00<?, ?it/s]/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/transformers/modeling_utils.py:862: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
 14%|█▍        | 1/7 [00:01<00:08,  1.43s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.20s/it] 43%|████▎     | 3/7 [00:03<00:04,  1.13s/it] 57%|█████▋    | 4/7 [00:04<00:03,  1.09s/it] 71%|███████▏  | 5/7 [00:05<00:02,  1.09s/it] 86%|████████▌ | 6/7 [00:06<00:01,  1.11s/it]100%|██████████| 7/7 [00:07<00:00,  1.13s/it]100%|██████████| 7/7 [00:07<00:00,  1.14s/it]
[32m[INFO] Using prompt [turn the dozer into red] and negative prompt [][0m
[32m[INFO] Using view-dependent prompts [side]:[turn the dozer into red, side view] [front]:[turn the dozer into red, front view] [back]:[turn the dozer into red, back view] [overhead]:[turn the dozer into red, overhead view][0m
[32m[INFO] Loading InstructPix2Pix ...[0m
Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]Loading pipeline components...:  40%|████      | 2/5 [00:01<00:02,  1.43it/s]Loading pipeline components...:  60%|██████    | 3/5 [00:08<00:06,  3.32s/it]Loading pipeline components...:  80%|████████  | 4/5 [00:10<00:02,  2.83s/it]Loading pipeline components...: 100%|██████████| 5/5 [00:10<00:00,  2.09s/it]
[32m[INFO] Loaded InstructPix2Pix![0m
/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0: |          | 0/? [00:00<?, ?it/s] /data2/manan/DGE/threestudio/systems/DGE.py:608: RuntimeWarning: invalid value encountered in arccos
  distances_with_sign = [np.arccos(np.dot(most_left_vecotr, cam.R[:, 2])) if np.dot(reference_axis,  np.cross(most_left_vecotr, cam.R[:, 2])) >= 0 else 2 * np.pi - np.arccos(np.dot(most_left_vecotr, cam.R[:, 2])) for cam in cams]
Start editing images...
Traceback (most recent call last):
  File "launch.py", line 253, in <module>
    main(args, extras)
  File "launch.py", line 196, in main
    trainer.fit(system, datamodule=dm, ckpt_path=cfg.resume)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/amp.py", line 80, in optimizer_step
    closure_result = closure()
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data2/anaconda3/envs/DGE/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/data2/manan/DGE/threestudio/systems/DGE.py", line 634, in training_step
    self.edit_all_view(original_render_name='origin_render', cache_name="edited_views", update_camera=self.true_global_step >= self.cfg.camera_update_per_step, global_step=self.true_global_step) 
  File "/data2/manan/DGE/threestudio/systems/DGE.py", line 590, in edit_all_view
    edited_images = self.guidance(
  File "/data2/manan/DGE/threestudio/models/guidance/dge_guidance.py", line 417, in __call__
    edit_latents = self.edit_latents(text_embeddings, latents, cond_latents, t, cams)   # 20 x 4 x 64 x 64
  File "/data2/manan/DGE/threestudio/models/guidance/dge_guidance.py", line 218, in edit_latents
    key_cams = [cams[cam_pivotal_idx] for cam_pivotal_idx in pivotal_idx.tolist()]  # len = 4
  File "/data2/manan/DGE/threestudio/models/guidance/dge_guidance.py", line 218, in <listcomp>
    key_cams = [cams[cam_pivotal_idx] for cam_pivotal_idx in pivotal_idx.tolist()]  # len = 4
IndexError: list index out of range
Epoch 0: |          | 0/? [00:03<?, ?it/s]